{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), 'Mrlishu'))\n",
    "if os.path.exists('/content'):\n",
    "    os.chdir('/content')\n",
    "    CODE_DIR = 'PHM-Tongji'\n",
    "    if not os.path.exists(CODE_DIR):\n",
    "        !git clone https://github.com/MrLishu/PHM-Tongji.git $CODE_DIR\n",
    "    os.chdir(f'./{CODE_DIR}')\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len = {}\n",
    "for i in (1, 4, 6):\n",
    "  len[f'c{i}'] = []\n",
    "  for j in range(315):\n",
    "    data = pd.read_csv(rf'/content/drive/MyDrive/PHM-Tongji/data/raw/PHM2010/c{i}/c_{i}_{j + 1:03d}.csv')\n",
    "    len[f'c{i}'].append(data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "\n",
    "\n",
    "class PHMDataset(Dataset):\n",
    "    def __init__(self, data_path, dataset_name, train=True, data_num=315, usecols=('Ax', 'Ay', 'Az'), resample_number=1024, step=1, totalscale=256, wavename='morl'):\n",
    "        self.data_path = data_path\n",
    "        self.dataset_name = dataset_name\n",
    "        self.train = train\n",
    "        self.data_num = data_num\n",
    "        self.usecols = usecols\n",
    "        self.resample_number = resample_number\n",
    "        self.step = step\n",
    "\n",
    "        self.signal_length = pd.read_csv(os.path.join(data_path, r'processed/PHM2010/signal_length.csv'))\n",
    "        self.labelset = {}\n",
    "        for name in dataset_name:\n",
    "          self.labelset[name] = pd.read_csv(os.path.join(data_path, rf'raw/PHM2010/{name}_wear.csv'))\n",
    "        self.columns = ['Fx', 'Fy', 'Fz', 'Ax', 'Ay', 'Az', 'Null']\n",
    "        sampling_rate = 50000\n",
    "\n",
    "        fc = pywt.central_frequency(wavename)\n",
    "        cparam = 2 * fc * totalscale\n",
    "        self.scales = cparam / np.arange(totalscale, 0, -1)\n",
    "        self.wavename = wavename\n",
    "        self.resample_rate = sampling_rate / step\n",
    "      \n",
    "    def __len__(self):\n",
    "        return self.data_num\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        name = self.dataset_name[idx // self.data_num]\n",
    "        ci = name[1]\n",
    "        i = idx % self.data_num\n",
    "        len = self.signal_length[name][i]\n",
    "\n",
    "        if self.train:\n",
    "            start = np.random.randint(len - self.resample_number * self.step)\n",
    "        else:\n",
    "            start = len - self.resample_number * self.step // 2\n",
    "        signal = pd.read_csv(os.path.join(self.data_path, rf'raw/PHM2010/{name}/c_{ci}_{i + 1:03d}.csv'), names=self.columns, usecols=self.usecols, skiprows=start, nrows=self.step * self.resample_number)\n",
    "        resampled = signal.to_numpy().T[:, ::self.step]\n",
    "\n",
    "        resampled -= resampled.mean(axis=-1)[:, np.newaxis]\n",
    "        resampled /= resampled.std(axis=-1)[:, np.newaxis]\n",
    "\n",
    "        cwtmatr, frequencies = pywt.cwt(resampled, self.scales, self.wavename, 1 / self.resample_rate)\n",
    "        cwtmatr = cwtmatr.transpose(1, 0, 2)\n",
    "\n",
    "        label = self.labelset[name].iloc[i, 1:].mean()\n",
    "        return cwtmatr, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V4vR9XMYSy2T"
   },
   "outputs": [],
   "source": [
    "train_dataset = PHMDataset(r'/content/drive/MyDrive/PHM-Tongji/data', ['c1', 'c4'])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y7wJrNRdWrYp"
   },
   "outputs": [],
   "source": [
    "data, label = next(iter(train_dataloader))\n",
    "data.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=False)\n",
    "# model.conv1 = nn.Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
    "model.fc = nn.Linear(in_features=512, out_features=1, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "scheduler = None\n",
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_table = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for step, (inputs, labels) in enumerate(train_dataloader):\n",
    "        model.train()\n",
    "        inputs = inputs.float().to(device)\n",
    "        labels = labels.float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels[:, np.newaxis])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "      \n",
    "    loss_table.append(running_loss)\n",
    "    print(f'Running loss: {running_loss:.3f}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
